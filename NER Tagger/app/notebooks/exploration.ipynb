{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3c33ccd-f49b-4651-8391-07a56a49b2d2",
   "metadata": {},
   "source": [
    "# NER\n",
    "    - Text & Labels\n",
    "    - Text $$\\implies$$ vocab (unique words in the corpus) + unknown token + padding token\n",
    "        - word2id and id2word\n",
    "    - Labels $\\implies$ tags (unique tags)\n",
    "        - tag2id and id2tag\n",
    "    \n",
    "    - conversion of texts i.e. sentences into tokens\n",
    "    - conversion of tokens into input ids with padding (maximum length of the sentences)\n",
    "    \n",
    "    - conversion of labels into label ids\n",
    "    - addition of padded tokens with label ids\n",
    "    \n",
    "    - If using Attention, make sure of attention masks\n",
    "    - Make sure of masks during loss calculation and metric calculation\n",
    "\n",
    "## Basic LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0179f981-e2e0-4c6b-9487-d0856ee90e24",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "- `words.txt` and `tags.txt` $\\rightarrow$ used to create the vocab and ner-tag maps\n",
    "- `train`, `test` and `val` folders each containing two files. For replication purposes.\n",
    "    - `sentences.txt` $\\rightarrow$ sentences in each line\n",
    "    - `labels.txt` $\\rightarrow$ corresponding ner-tags of each sentences\n",
    "    \n",
    "**Note: As the dataset is already partitioned the dataset class that will manage the data operations can directly read the data and address the necessary modifications.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dfb3ca-d4c7-44f4-94ad-14b531c7fbf3",
   "metadata": {},
   "source": [
    "## Vocab & Tag Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a10daa48-270a-44e1-90c8-f93fbb0b5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_path = '../data/words.txt'\n",
    "tags_path = '../data/tags.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "180957b1-0bb0-4c85-9735-9d68a9cdc34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thousands: \t 0 \tUknown:\t 35179 \tPAD\t 35180\n",
      "\n",
      "('Thousands', 0)\n",
      "..................................................\n",
      "('of', 1)\n",
      "..................................................\n",
      "('demonstrators', 2)\n",
      "..................................................\n",
      "('have', 3)\n",
      "..................................................\n",
      "('marched', 4)\n",
      "..................................................\n",
      "('through', 5)\n",
      "..................................................\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "with open(words_path) as f:\n",
    "    for i, l in enumerate(f.read().splitlines()):\n",
    "        vocab[l] = i\n",
    "vocab['<PAD>'] = len(vocab)\n",
    "\n",
    "print(\"Thousands: \\t\", vocab['Thousands'], \"\\tUknown:\\t\", vocab['UNK'], \"\\tPAD\\t\", vocab['<PAD>'])\n",
    "print()\n",
    "c = 0\n",
    "for i in vocab.items():\n",
    "    print(i)\n",
    "    print('.'*50)\n",
    "    c += 1\n",
    "    if c > 5: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f72b226-fd25-4d02-98a1-008fc03f45a5",
   "metadata": {},
   "source": [
    "- A `<PAD>` token is set which will be used to pad the sentences upto the maximum length of the sequences\n",
    "- An `UNK` token is added to address out of vocabulary words/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7b46d2c-2920-4422-bd2f-7eac90e10e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'O': 0,\n",
       " 'B-geo': 1,\n",
       " 'B-gpe': 2,\n",
       " 'B-per': 3,\n",
       " 'I-geo': 4,\n",
       " 'B-org': 5,\n",
       " 'I-org': 6,\n",
       " 'B-tim': 7,\n",
       " 'B-art': 8,\n",
       " 'I-art': 9,\n",
       " 'I-per': 10,\n",
       " 'I-gpe': 11,\n",
       " 'I-tim': 12,\n",
       " 'B-nat': 13,\n",
       " 'B-eve': 14,\n",
       " 'I-eve': 15,\n",
       " 'I-nat': 16}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_map = {}\n",
    "with open(tags_path) as f:\n",
    "    for i, t in enumerate(f.read().splitlines()):\n",
    "        tag_map[t] = i\n",
    "\n",
    "tag_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed919c1-4b7b-4080-91ad-1e8cb6f09fe1",
   "metadata": {},
   "source": [
    "## Loading Training data and performing Transformations\n",
    "- Same will be applicable for both test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8fb87de-d058-4b7f-9121-90031aaf2d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .\n",
      "....................................................................................................\n",
      "Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \"\n",
      "....................................................................................................\n",
      "They marched from the Houses of Parliament to a rally in Hyde Park .\n",
      "....................................................................................................\n",
      "Police put the number of marchers at 10,000 while organizers claimed it was 1,00,000 .\n",
      "....................................................................................................\n",
      "The protest comes on the eve of the annual conference of Britain 's ruling Labor Party in the southern English seaside resort of Brighton .\n",
      "....................................................................................................\n"
     ]
    }
   ],
   "source": [
    "# Load Data in lists\n",
    "with open(\"../data/train/sentences.txt\", \"r\") as f:\n",
    "    sentences = f.read().splitlines()\n",
    "    \n",
    "for i in sentences[:5]:\n",
    "    print(i)\n",
    "    print('.' * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11bcb43a-d6b0-4bce-aab3-ed75a4a113ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O O O O O O B-geo O O O O O B-geo O O O O O B-gpe O O O O O\n",
      "....................................................................................................\n",
      "O O O O O O O O O O O O O O O O O O B-per O O O O O O O O O O O\n",
      "....................................................................................................\n",
      "O O O O O O O O O O O B-geo I-geo O\n",
      "....................................................................................................\n",
      "O O O O O O O O O O O O O O O\n",
      "....................................................................................................\n",
      "O O O O O O O O O O O B-geo O O B-org I-org O O O B-gpe O O O B-geo O\n",
      "....................................................................................................\n"
     ]
    }
   ],
   "source": [
    "# Load Data in lists\n",
    "with open(\"../data/train/labels.txt\", \"r\") as f:\n",
    "    labels = f.read().splitlines()\n",
    "    \n",
    "for i in labels[:5]:\n",
    "    print(i)\n",
    "    print('.' * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbbd7a7-f1e2-46be-b991-6be34a33d770",
   "metadata": {},
   "source": [
    "## Data Conversion\n",
    "- Convert sentences into list of id's based on the word2id $\\rightarrow$ vocab mapping\n",
    "- Convert tags in to list of tag id's based on the tag2id $\\rightarrow$ tags mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7752f1-946d-4c74-941d-7deb00b577d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict\n",
    "import random\n",
    "random.seed(518123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58e54d2d-dfef-489a-b28a-9d5090867c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence2id(sentence: str, vocab_map: Dict) -> List:\n",
    "    sentence_id = []\n",
    "    for token in sentence.split(' '):\n",
    "        if token in vocab_map:\n",
    "            sentence_id.append(vocab_map[token])\n",
    "        else:\n",
    "            sentence_id.append(vocab_map['UNK'])\n",
    "    return sentence_id            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40b789bc-b996-4f51-a36c-68d2345ef84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tags2id(tag_list: str, tag_map: Dict) -> List:\n",
    "    tag_id = []\n",
    "    for label in tag_list.split(' '):\n",
    "        tag_id.append(tag_map[label])\n",
    "    return tag_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a5ba507-374f-424a-ba92-fd8e248c794c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a statement Monday , Mr. Peres said \" there exists no basis in reality for the claims published \" by the British newspaper , The Guardian .\n",
      "..............................................................................................................................................\n",
      "[345, 45, 1171, 1564, 93, 816, 8887, 172, 35, 596, 10871, 388, 2051, 11, 7814, 223, 9, 2865, 2573, 35, 191, 9, 16, 1765, 93, 61, 2646, 21]\n",
      "\n",
      "O O O B-tim O B-per I-per O O O O O O O O O O O O O O O B-gpe O O B-org I-org O\n",
      "...............................................................................\n",
      "[0, 0, 0, 7, 0, 3, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 5, 6, 0]\n"
     ]
    }
   ],
   "source": [
    "rand_id = random.choice(range(len(sentences)))\n",
    "rand_sent = sentences[rand_id]\n",
    "print(rand_sent)\n",
    "print('.'*len(rand_sent))\n",
    "print(convert_sentence2id(rand_sent, vocab_map=vocab))\n",
    "print()\n",
    "rand_labels = labels[rand_id]\n",
    "print(rand_labels)\n",
    "print('.'*len(rand_labels))\n",
    "print(convert_tags2id(rand_labels, tag_map=tag_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1efbce99-0d92-42fe-b40a-cee05ee0a510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(sentences) == len(labels)\n",
    "for s, l in zip(sentences, labels):\n",
    "    try:\n",
    "        assert len(s.split(' ')) == len(l.split(' '))\n",
    "    except AssertionError:\n",
    "        print(s, l)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7e6570-139a-47be-bdec-5660ec55735b",
   "metadata": {},
   "source": [
    "## Dataclass\n",
    "- Pass the lists into torch dataset/data-generator class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fadec35-243f-4eb8-a435-02ec5e274564",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentence = \"../data/train/sentences.txt\"\n",
    "train_labels = \"../data/train/labels.txt\"\n",
    "\n",
    "valid_sentence = \"../data/val/sentences.txt\"\n",
    "valid_labels = \"../data/val/labels.txt\"\n",
    "\n",
    "test_sentence = \"../data/test/sentences.txt\"\n",
    "test_labels = \"../data/test/labels.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b6fbc30-d4e2-4762-8590-767c06ace482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07a9ab80-44a9-4ccf-bda0-59d6f86e43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ner_data(Dataset):\n",
    "    \n",
    "    def __init__(self, sentences_path: str, labels_path: str, vocab_map: Dict, tags_map: Dict) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        with open(sentences_path, \"r\") as f:\n",
    "            self.sentences = f.read().splitlines()\n",
    "        \n",
    "        with open(labels_path, \"r\") as f:\n",
    "            self.labels = f.read().splitlines()\n",
    "            \n",
    "        self.max_len = max([len(sentence) for sentence in self.sentences])\n",
    "        self.vocab_map = vocab_map\n",
    "        self.tags_map = tags_map\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sentence_padded = np.array(self.max_len * [vocab[\"<PAD>\"]])\n",
    "        labels_padded = np.array(self.max_len * [vocab[\"<PAD>\"]])\n",
    "        \n",
    "        sentence = convert_sentence2id(self.sentences[idx], self.vocab_map)\n",
    "        labels = convert_tags2id(self.labels[idx], self.tags_map)\n",
    "        \n",
    "        assert len(sentence) == len(labels)\n",
    "        \n",
    "        sentence_padded[:len(sentence)] = sentence\n",
    "        labels_padded[:len(labels)] = labels\n",
    "        \n",
    "        return torch.tensor(sentence_padded, dtype=torch.long), torch.tensor(labels_padded, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bece194-3592-4b03-89ad-3fa1247db8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_train = ner_data(sentences_path=train_sentence,\n",
    "                     labels_path=train_labels,\n",
    "                     vocab_map=vocab,\n",
    "                     tags_map=tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe436d54-6d53-48e8-b46f-51f7f2de7350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(541, 33570)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_train.max_len, len(ner_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e716230-4169-4a2b-baff-f3a869aa675d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n",
      "torch.Size([541]) torch.Size([541])\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    data = ner_train.__getitem__(i)\n",
    "    print(data[0].shape, data[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78075ef8-0b76-41d7-9394-c71992ced495",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "train_loader = DataLoader(dataset=ner_train, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bd6cf14-3d22-4252-9b27-b818df9742fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c8ee8fd-5a78-4068-b85d-5e6c810e81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_batch = next(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6f59669-e373-4c9c-9442-20d94806795d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 541]), torch.Size([512, 541]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch[0].shape, data_batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53446252-4b8c-43cb-b573-47fea8ef13fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ner_data_loader(sentences_path, labels_path, vocab_map, tags_map,\n",
    "                           batch_size=8, shuffle=True, num_workers=4):\n",
    "    \n",
    "    ner = ner_data(sentences_path, labels_path, vocab_map, tags_map)\n",
    "    \n",
    "    return DataLoader(dataset=ner, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c0a65f5-3256-48a0-9279-11aa46d99e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_ner_data_loader(train_sentence, train_labels, vocab, tag_map, batch_size=batch_size)\n",
    "valid_loader = create_ner_data_loader(valid_sentence, valid_labels, vocab, tag_map, batch_size=batch_size)\n",
    "test_loader = create_ner_data_loader(test_sentence, test_labels, vocab, tag_map, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6da3f94-0f33-4d0f-be5c-0aa7f84dec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "vl = iter(valid_loader)\n",
    "valid_data = next(vl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "998a12aa-9e34-47d2-bea6-b2c2b85925cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 424]), torch.Size([512, 424]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data[0].shape, valid_data[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb79b39-e10b-469e-b6f4-52b53fed0e55",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "079f536b-94f4-4240-8e2c-cd1e2bf7ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NER_Tagger(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size: int, embedding_size: int, dense_output_size: int, device: str = 'cpu') -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
    "        self.lstm = nn.LSTM(embedding_size, embedding_size//2, batch_first=True)\n",
    "        self.dense = nn.Linear(embedding_size//2, dense_output_size)\n",
    "        \n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        processed --> will have 3 outputs\n",
    "            - hidden states for each input sequence\n",
    "            - final hidden state for each element in the sequence\n",
    "            - final cell state for each element in the sequence\n",
    "            \n",
    "        processed[0].shape = (batch_size, sequence_length, h_out_size)\n",
    "        cessed[1][0].shape = (1, batch_size, h_out_size)\n",
    "        processed[1][1].shape = (1, batch_size, h_out_size)\n",
    "        \"\"\"\n",
    "        \n",
    "        embedded = self.embedding(X)\n",
    "        processed = self.lstm(embedded)\n",
    "        processed = self.dense(processed[0])\n",
    "        return F.log_softmax(processed, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ffe960e-6bb9-40b0-81ed-426c05a9ab34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NER_Tagger(\n",
       "  (embedding): Embedding(35181, 50)\n",
       "  (lstm): LSTM(50, 25, batch_first=True)\n",
       "  (dense): Linear(in_features=25, out_features=17, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger = NER_Tagger(len(vocab), 50, len(tag_map))\n",
    "tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eef25331-dccd-4efa-87ff-7ec6535636f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-3.0022, -2.9203, -2.9438,  ..., -2.9484, -2.8224, -2.7614],\n",
       "         [-2.9889, -2.6462, -2.9306,  ..., -2.7803, -2.8264, -2.8393],\n",
       "         [-2.9105, -2.7030, -2.9933,  ..., -2.6913, -2.7873, -2.9711],\n",
       "         ...,\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529]],\n",
       "\n",
       "        [[-3.1038, -2.7061, -2.7388,  ..., -2.8788, -2.8103, -2.7535],\n",
       "         [-2.9590, -2.7851, -2.7770,  ..., -2.7818, -2.8435, -2.7850],\n",
       "         [-3.0146, -2.7110, -2.7457,  ..., -2.7651, -2.8989, -2.7158],\n",
       "         ...,\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529]],\n",
       "\n",
       "        [[-2.8991, -2.8902, -2.7869,  ..., -2.8971, -2.7908, -2.6116],\n",
       "         [-2.9473, -2.8656, -2.9165,  ..., -2.9511, -2.8256, -2.6353],\n",
       "         [-3.0719, -2.7984, -2.8665,  ..., -2.8447, -2.8570, -2.7070],\n",
       "         ...,\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.8316, -2.8810, -2.9158,  ..., -2.7567, -2.9539, -2.7987],\n",
       "         [-2.8625, -2.8839, -2.8301,  ..., -2.7863, -2.8679, -2.7218],\n",
       "         [-2.9735, -2.8053, -2.8063,  ..., -2.7883, -2.9367, -2.8157],\n",
       "         ...,\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529]],\n",
       "\n",
       "        [[-2.8878, -2.7536, -2.8157,  ..., -2.7414, -2.8925, -2.7588],\n",
       "         [-2.8234, -2.8682, -2.9816,  ..., -2.7634, -2.8338, -2.7115],\n",
       "         [-2.7364, -2.7949, -2.9354,  ..., -2.7316, -2.9773, -2.7539],\n",
       "         ...,\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529]],\n",
       "\n",
       "        [[-2.7871, -2.9013, -3.0369,  ..., -2.7771, -2.8677, -2.8201],\n",
       "         [-2.7498, -2.9657, -3.0020,  ..., -2.9058, -2.9802, -2.7017],\n",
       "         [-2.7542, -2.9243, -2.9937,  ..., -2.7839, -2.8327, -2.7545],\n",
       "         ...,\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529],\n",
       "         [-2.7820, -3.0221, -3.1874,  ..., -2.6801, -2.5884, -2.8529]]],\n",
       "       grad_fn=<LogSoftmaxBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tags = tagger(data_batch[0])\n",
    "predicted_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7dfb896-aab6-42eb-9ff9-601a87ee2370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512, 541, 17]), torch.Size([541, 17]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_tags.shape, predicted_tags[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1124dd8a-7fc7-4942-8884-cae673c18051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 541])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(predicted_tags, dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ced61ae-f078-4bee-b2dc-f859076f036a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,  ..., 35180, 35180, 35180],\n",
       "        [    0,     3,    10,  ..., 35180, 35180, 35180],\n",
       "        [    0,     0,     0,  ..., 35180, 35180, 35180],\n",
       "        ...,\n",
       "        [    2,     0,     0,  ..., 35180, 35180, 35180],\n",
       "        [    0,     0,     0,  ..., 35180, 35180, 35180],\n",
       "        [    2,     0,     1,  ..., 35180, 35180, 35180]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9ab088a2-331e-40b2-8741-714e384b4c5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(predicted_tags, dim=-1) == data_batch[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4372101-fc83-4726-abec-e2d2feba1c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        ...,\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ..., False, False, False]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_mask = data_batch[1] != vocab['<PAD>']\n",
    "pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65683c26-8b5f-491d-9ac0-0d482f362153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(134), tensor(10733), tensor(0.0125))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((torch.argmax(predicted_tags, dim=-1) == data_batch[1]) * pad_mask).sum(), pad_mask.sum(), ((torch.argmax(predicted_tags, dim=-1) == data_batch[1]) * pad_mask).sum() / pad_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb05d480-c976-4cf9-bfb7-ed014b6a8c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 0,  3, 10,  ...,  0,  0,  0],\n",
       "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 2,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 0,  0,  0,  ...,  0,  0,  0],\n",
       "        [ 2,  0,  1,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_batch[1] * pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83d178f5-4fa1-4efe-ae8b-d9b670b67d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d7deac-443f-464c-a0c1-c25b19b7debb",
   "metadata": {},
   "source": [
    "## Check to see the operations on dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5521733e-eca5-4270-8607-f02cd0571770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2670, 0.3764, 0.5874],\n",
       "         [0.6756, 0.2998, 0.3733],\n",
       "         [0.1682, 0.3479, 0.3727],\n",
       "         [0.2941, 0.7707, 0.8221]],\n",
       "\n",
       "        [[0.8323, 0.9966, 0.3166],\n",
       "         [0.6257, 0.4427, 0.6233],\n",
       "         [0.7246, 0.2789, 0.5361],\n",
       "         [0.2861, 0.7712, 0.1433]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((2, 4, 3))\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6dcf619-5559-4952-a354-1b6d960e518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.2509, -1.1414, -0.9305],\n",
       "         [-0.8862, -1.2620, -1.1885],\n",
       "         [-1.2307, -1.0510, -1.0263],\n",
       "         [-1.4601, -0.9834, -0.9321]],\n",
       "\n",
       "        [[-1.0209, -0.8566, -1.5366],\n",
       "         [-1.0404, -1.2234, -1.0428],\n",
       "         [-0.9036, -1.3494, -1.0922],\n",
       "         [-1.2502, -0.7652, -1.3931]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_log_softmax = F.log_softmax(X, dim=-1)\n",
    "test_log_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d45c16ef-d474-42a6-83cc-d8867fa42016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000, 1.0000],\n",
       "        [1.0000, 1.0000, 1.0000, 1.0000]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(test_log_softmax).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e61bb75-107a-460c-adbf-19ddc82e93fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cost Function and Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab9e2b9-29c9-4bfb-a26e-d06c12f8fb3b",
   "metadata": {},
   "source": [
    "### Device Setup, Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2282ae3f-0460-4134-be8f-d99f4c6bd86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c13c7dcba2f8447799d8b57d41de363d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i in tqdm(range(1000), dynamic_ncols=True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c21e238c-2369-49f2-8cfe-a33540ac660a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_evaluation(predictions, true_labels, pad_value):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "        pred: prediction array with shape -> (num_examples, max sentence length in batch)\n",
    "        labels: array of size (batch_size, seq_len)\n",
    "        pad: integer representing pad character\n",
    "    Outputs:\n",
    "        accuracy: float\n",
    "    \"\"\"\n",
    "    # Create mask matrix equal to the shape of the true-labels matrix\n",
    "    pad_mask = true_labels != pad_value\n",
    "    \n",
    "    # Calculate Accuracy\n",
    "    accuracy = ((predictions == true_labels) * pad_mask).sum() / pad_mask.sum()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1553cc90-8f28-4a19-9a7d-55d9fe98d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# device = 'cpu'\n",
    "\n",
    "\n",
    "lr = 1e-2\n",
    "lr_step_size = 2           # every 2 epochs\n",
    "lr_reduction_pc = 0.95     # 95% reduction of lr\n",
    "\n",
    "grad_clip_threshold = 0.3\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "tagger = NER_Tagger(vocab_size=len(vocab), embedding_size=50, dense_size=len(tag_map), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3ff41613-0e0a-4bf1-bf68-9fa01b485b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss/Cost Function\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index=vocab['<PAD>']).to(device)\n",
    "\n",
    "# Optimizer --> model parameters and learning rate\n",
    "# Class weights can also be specified if necessary\n",
    "optimizer = torch.optim.Adam(params=tagger.parameters(), lr=lr)\n",
    "\n",
    "# learning rate scheduler --> slow reduction of learning rate from a higher value\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=lr_step_size, gamma=lr_reduction_pc)\n",
    "\n",
    "# dl tricks\n",
    "#    gradient clippings --> to avoid vanishing gradient or gradient explosion\n",
    "gradient_clip = nn.utils.clip_grad_value_\n",
    "gradient_clip(parameters=tagger.parameters(), clip_value=grad_clip_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d604417-0955-4d6e-b8c2-d34b13ce31f9",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "517dcf41-3c88-4ab1-9bdb-5a3291c848e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953fb072e815427bbf8d061a3266b27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch Progress:   0%|                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae3a4ea4d8cb4a19b7de83868892d1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|                                                                                      …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   66 steps  --- Accuracy 0.8179  |  Epoch Loss  0.8612\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311507d1ad5f452a9d7387091988481c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.8819\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf8913e59454834b267aeebaa0b2a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|                                                                                      …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  132 steps  --- Accuracy 0.9111  |  Epoch Loss  0.3355\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1a338e01724459840c83226c52bd04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.9393\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f44a21a141c441e78f04a880dc4a8d6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|                                                                                      …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  198 steps  --- Accuracy 0.9470  |  Epoch Loss  0.1983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f05163b3d24ab3a1e9a985484104be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.9568\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7516ef7349f4464da63817a846154a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|                                                                                      …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  264 steps  --- Accuracy 0.9586  |  Epoch Loss  0.1481\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdfceebf228a4e5bb6c5704676633a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.9638\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b461c2e87a54048b450d27834c6a1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Progress:   0%|                                                                                      …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training  330 steps  --- Accuracy 0.9642  |  Epoch Loss  0.1235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc7dc7833d44b7b9bfd1acd72ec574b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Progress:   0%|                                                                                    …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy 0.9680\n"
     ]
    }
   ],
   "source": [
    "validation_metric_tracker = []\n",
    "steps = 0\n",
    "\n",
    "# Epoch Loop --> 1 epoch is one forward pass through all the training data\n",
    "for epoch in tqdm(range(epochs), dynamic_ncols=True, desc='Epoch Progress'):\n",
    "\n",
    "    # set model to training mode\n",
    "    tagger.train()\n",
    "    epoch_loss, train_predictions = [], []\n",
    "\n",
    "    # training loop for each mini-batch\n",
    "    for sentences, true_tags in tqdm(train_loader, dynamic_ncols=True, desc='Training Progress'):\n",
    "        # set grads to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        sentences, true_tags = sentences.to(device), true_tags.to(device)\n",
    "        predicted_tags = tagger(sentences)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = loss_function(predicted_tags.view(-1, predicted_tags.shape[2]),\n",
    "                             true_tags.view(-1))\n",
    "\n",
    "        # Track Loss for each epoch\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        # calculate training metrics\n",
    "        train_accuracy = prediction_evaluation(torch.argmax(predicted_tags, dim=-1), true_tags, pad_value=vocab['<PAD>'])\n",
    "        train_predictions.append(train_accuracy.item())\n",
    "\n",
    "        # backward pass i.e. gradient calculations\n",
    "        loss.backward()\n",
    "\n",
    "        # optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        # increment training steps\n",
    "        steps += 1\n",
    "\n",
    "    print('Training {:>4d} steps  --- Accuracy {:>5.4f}  |  Epoch Loss  {:>5.4f}'.format(steps, np.mean(train_predictions),\n",
    "                                                                                     np.mean(epoch_loss)))\n",
    "    \n",
    "    # validation loop after each training epoch\n",
    "    # set no grad\n",
    "    with torch.no_grad():\n",
    "        tagger.eval()\n",
    "        validation_predictions = []\n",
    "        \n",
    "        # perform validation\n",
    "        # validation loop for each mini-batch\n",
    "        for val_sentences, val_true_tags in tqdm(train_loader, dynamic_ncols=True, desc='Validation Progress'):\n",
    "            \n",
    "            val_sentences, val_true_tags = val_sentences.to(device), val_true_tags.to(device)\n",
    "            predicted_tags = tagger(val_sentences)\n",
    "            \n",
    "            # calculate validation metrics\n",
    "            validation_accuracy = prediction_evaluation(torch.argmax(predicted_tags, dim=-1), val_true_tags, pad_value=vocab['<PAD>'])\n",
    "            validation_predictions.append(validation_accuracy.item())\n",
    "        \n",
    "        print('Validation Accuracy {:>5.4f}'.format(np.mean(validation_predictions)))\n",
    "    \n",
    "    lr_scheduler.step()\n",
    "\n",
    "# save checkpoint (conditioned on performance or time-steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267abc6c-e9f7-4f78-9e0c-23c2fe04649f",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c09580a-b6cd-4208-9d91-bc676baf50d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validator = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b35c006f-68e7-4440-a91e-227de14533bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = validator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bd6e568-e17d-47eb-b00e-70ea8bd4235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.to('cuda')\n",
    "predicted_test = tagger(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5620307c-2c3f-4a76-81a6-eb8860246199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9502)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_evaluation(torch.argmax(predicted_test, dim=-1).detach().cpu(), y_test, pad_value=vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "58925b9a-2274-4180-baf0-eda5f97868f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tags = torch.argmax(predicted_test, dim=-1).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "811e1b0e-c006-421f-a0b4-99ff49e1b69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = y_test[0] != vocab['<PAD>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fda95808-3238-4edd-998c-9d5228549678",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-geo',\n",
       " 2: 'B-gpe',\n",
       " 3: 'B-per',\n",
       " 4: 'I-geo',\n",
       " 5: 'B-org',\n",
       " 6: 'I-org',\n",
       " 7: 'B-tim',\n",
       " 8: 'B-art',\n",
       " 9: 'I-art',\n",
       " 10: 'I-per',\n",
       " 11: 'I-gpe',\n",
       " 12: 'I-tim',\n",
       " 13: 'B-nat',\n",
       " 14: 'B-eve',\n",
       " 15: 'I-eve',\n",
       " 16: 'I-nat'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_tag_map = {v:k for k, v in tag_map.items()}\n",
    "reverse_tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0f7b95f-c3df-4a99-832f-31e65f371ed6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Thousands',\n",
       " 1: 'of',\n",
       " 2: 'demonstrators',\n",
       " 3: 'have',\n",
       " 4: 'marched',\n",
       " 5: 'through',\n",
       " 6: 'London',\n",
       " 7: 'to',\n",
       " 8: 'protest',\n",
       " 9: 'the',\n",
       " 10: 'war',\n",
       " 11: 'in',\n",
       " 12: 'Iraq',\n",
       " 13: 'and',\n",
       " 14: 'demand',\n",
       " 15: 'withdrawal',\n",
       " 16: 'British',\n",
       " 17: 'troops',\n",
       " 18: 'from',\n",
       " 19: 'that',\n",
       " 20: 'country',\n",
       " 21: '.',\n",
       " 22: 'Families',\n",
       " 23: 'soldiers',\n",
       " 24: 'killed',\n",
       " 25: 'conflict',\n",
       " 26: 'joined',\n",
       " 27: 'protesters',\n",
       " 28: 'who',\n",
       " 29: 'carried',\n",
       " 30: 'banners',\n",
       " 31: 'with',\n",
       " 32: 'such',\n",
       " 33: 'slogans',\n",
       " 34: 'as',\n",
       " 35: '\"',\n",
       " 36: 'Bush',\n",
       " 37: 'Number',\n",
       " 38: 'One',\n",
       " 39: 'Terrorist',\n",
       " 40: 'Stop',\n",
       " 41: 'Bombings',\n",
       " 42: 'They',\n",
       " 43: 'Houses',\n",
       " 44: 'Parliament',\n",
       " 45: 'a',\n",
       " 46: 'rally',\n",
       " 47: 'Hyde',\n",
       " 48: 'Park',\n",
       " 49: 'Police',\n",
       " 50: 'put',\n",
       " 51: 'number',\n",
       " 52: 'marchers',\n",
       " 53: 'at',\n",
       " 54: '10,000',\n",
       " 55: 'while',\n",
       " 56: 'organizers',\n",
       " 57: 'claimed',\n",
       " 58: 'it',\n",
       " 59: 'was',\n",
       " 60: '1,00,000',\n",
       " 61: 'The',\n",
       " 62: 'comes',\n",
       " 63: 'on',\n",
       " 64: 'eve',\n",
       " 65: 'annual',\n",
       " 66: 'conference',\n",
       " 67: 'Britain',\n",
       " 68: \"'s\",\n",
       " 69: 'ruling',\n",
       " 70: 'Labor',\n",
       " 71: 'Party',\n",
       " 72: 'southern',\n",
       " 73: 'English',\n",
       " 74: 'seaside',\n",
       " 75: 'resort',\n",
       " 76: 'Brighton',\n",
       " 77: 'party',\n",
       " 78: 'is',\n",
       " 79: 'divided',\n",
       " 80: 'over',\n",
       " 81: 'participation',\n",
       " 82: 'continued',\n",
       " 83: 'deployment',\n",
       " 84: '8,500',\n",
       " 85: 'march',\n",
       " 86: 'came',\n",
       " 87: 'ahead',\n",
       " 88: 'anti-war',\n",
       " 89: 'protests',\n",
       " 90: 'today',\n",
       " 91: 'other',\n",
       " 92: 'cities',\n",
       " 93: ',',\n",
       " 94: 'including',\n",
       " 95: 'Rome',\n",
       " 96: 'Paris',\n",
       " 97: 'Madrid',\n",
       " 98: 'International',\n",
       " 99: 'Atomic',\n",
       " 100: 'Energy',\n",
       " 101: 'Agency',\n",
       " 102: 'hold',\n",
       " 103: 'second',\n",
       " 104: 'day',\n",
       " 105: 'talks',\n",
       " 106: 'Vienna',\n",
       " 107: 'Wednesday',\n",
       " 108: 'how',\n",
       " 109: 'respond',\n",
       " 110: 'Iran',\n",
       " 111: 'resumption',\n",
       " 112: 'low-level',\n",
       " 113: 'uranium',\n",
       " 114: 'conversion',\n",
       " 115: 'this',\n",
       " 116: 'week',\n",
       " 117: 'restarted',\n",
       " 118: 'parts',\n",
       " 119: 'process',\n",
       " 120: 'its',\n",
       " 121: 'Isfahan',\n",
       " 122: 'nuclear',\n",
       " 123: 'plant',\n",
       " 124: 'Iranian',\n",
       " 125: 'officials',\n",
       " 126: 'say',\n",
       " 127: 'they',\n",
       " 128: 'expect',\n",
       " 129: 'get',\n",
       " 130: 'access',\n",
       " 131: 'sealed',\n",
       " 132: 'sensitive',\n",
       " 133: 'after',\n",
       " 134: 'an',\n",
       " 135: 'IAEA',\n",
       " 136: 'surveillance',\n",
       " 137: 'system',\n",
       " 138: 'begins',\n",
       " 139: 'functioning',\n",
       " 140: 'step',\n",
       " 141: 'will',\n",
       " 142: 'allow',\n",
       " 143: 'facility',\n",
       " 144: 'operate',\n",
       " 145: 'full',\n",
       " 146: 'capacity',\n",
       " 147: 'European',\n",
       " 148: 'Union',\n",
       " 149: 'U.S.',\n",
       " 150: 'backing',\n",
       " 151: 'has',\n",
       " 152: 'threatened',\n",
       " 153: 'refer',\n",
       " 154: 'U.N.',\n",
       " 155: 'Security',\n",
       " 156: 'Council',\n",
       " 157: 'which',\n",
       " 158: 'could',\n",
       " 159: 'impose',\n",
       " 160: 'sanctions',\n",
       " 161: 'if',\n",
       " 162: 'finds',\n",
       " 163: 'Tehran',\n",
       " 164: 'violated',\n",
       " 165: 'Nuclear',\n",
       " 166: 'Non-Proliferation',\n",
       " 167: 'treaty',\n",
       " 168: 'new',\n",
       " 169: 'President',\n",
       " 170: 'Mahmoud',\n",
       " 171: 'Ahmadinejad',\n",
       " 172: 'said',\n",
       " 173: 'Tuesday',\n",
       " 174: 'incentives',\n",
       " 175: 'aimed',\n",
       " 176: 'persuading',\n",
       " 177: 'end',\n",
       " 178: 'fuel',\n",
       " 179: 'program',\n",
       " 180: 'are',\n",
       " 181: 'insult',\n",
       " 182: 'nation',\n",
       " 183: 'Two',\n",
       " 184: 'Germans',\n",
       " 185: 'four',\n",
       " 186: 'Nigerian',\n",
       " 187: 'oil',\n",
       " 188: 'workers',\n",
       " 189: 'were',\n",
       " 190: 'kidnapped',\n",
       " 191: 'by',\n",
       " 192: 'armed',\n",
       " 193: 'militants',\n",
       " 194: 'during',\n",
       " 195: 'raid',\n",
       " 196: 'boat',\n",
       " 197: 'Nigeria',\n",
       " 198: 'oil-rich',\n",
       " 199: 'Delta',\n",
       " 200: 'region',\n",
       " 201: 'An',\n",
       " 202: 'official',\n",
       " 203: 'German',\n",
       " 204: 'firm',\n",
       " 205: 'Bilfinger',\n",
       " 206: 'Berger',\n",
       " 207: 'Thomas',\n",
       " 208: 'Horbach',\n",
       " 209: 'gunmen',\n",
       " 210: 'stopped',\n",
       " 211: 'supply',\n",
       " 212: 'sailed',\n",
       " 213: 'State',\n",
       " 214: 'Bayelsa',\n",
       " 215: 'inspect',\n",
       " 216: 'offshore',\n",
       " 217: 'field',\n",
       " 218: 'owned',\n",
       " 219: 'Royal-Dutch',\n",
       " 220: 'Shell',\n",
       " 221: 'works',\n",
       " 222: 'sub-contractor',\n",
       " 223: 'for',\n",
       " 224: 'Militant',\n",
       " 225: 'groups',\n",
       " 226: 'frequently',\n",
       " 227: 'attack',\n",
       " 228: 'operations',\n",
       " 229: 'Niger',\n",
       " 230: 'social',\n",
       " 231: 'services',\n",
       " 232: 'better',\n",
       " 233: 'job',\n",
       " 234: 'opportunities',\n",
       " 235: 'multinational',\n",
       " 236: 'companies',\n",
       " 237: 'Poor',\n",
       " 238: 'residents',\n",
       " 239: 'often',\n",
       " 240: 'complain',\n",
       " 241: 'been',\n",
       " 242: 'cheated',\n",
       " 243: 'out',\n",
       " 244: 'huge',\n",
       " 245: 'riches',\n",
       " 246: 'extracted',\n",
       " 247: 'their',\n",
       " 248: 'tribal',\n",
       " 249: 'lands',\n",
       " 250: '-',\n",
       " 251: 'where',\n",
       " 252: 'bulk',\n",
       " 253: '2.3',\n",
       " 254: 'million',\n",
       " 255: 'barrels',\n",
       " 256: 'petroleum',\n",
       " 257: 'pumped',\n",
       " 258: 'daily',\n",
       " 259: 'Suspected',\n",
       " 260: 'Islamist',\n",
       " 261: 'rebels',\n",
       " 262: 'fired',\n",
       " 263: 'mortar',\n",
       " 264: 'shells',\n",
       " 265: 'palace',\n",
       " 266: 'used',\n",
       " 267: 'Somalia',\n",
       " 268: 'interim',\n",
       " 269: 'Abdullahi',\n",
       " 270: 'Yusuf',\n",
       " 271: 'Ahmad',\n",
       " 272: 'It',\n",
       " 273: 'not',\n",
       " 274: 'immediately',\n",
       " 275: 'clear',\n",
       " 276: 'president',\n",
       " 277: 'Mogadishu',\n",
       " 278: 'when',\n",
       " 279: 'occurred',\n",
       " 280: 'or',\n",
       " 281: 'anyone',\n",
       " 282: 'hurt',\n",
       " 283: 'Local',\n",
       " 284: 'news',\n",
       " 285: 'reports',\n",
       " 286: 'least',\n",
       " 287: 'five',\n",
       " 288: 'hit',\n",
       " 289: 'compound',\n",
       " 290: 'mortars',\n",
       " 291: 'elsewhere',\n",
       " 292: 'attacks',\n",
       " 293: 'government',\n",
       " 294: 'go',\n",
       " 295: 'reconciliation',\n",
       " 296: 'more',\n",
       " 297: 'than',\n",
       " 298: '1,300',\n",
       " 299: 'Somali',\n",
       " 300: 'elders',\n",
       " 301: 'warlords',\n",
       " 302: 'politicians',\n",
       " 303: 'invited',\n",
       " 304: 'Iraqi',\n",
       " 305: 'military',\n",
       " 306: 'tanks',\n",
       " 307: 'arrived',\n",
       " 308: 'northern',\n",
       " 309: 'city',\n",
       " 310: 'Mosul',\n",
       " 311: 'offensive',\n",
       " 312: 'against',\n",
       " 313: 'al',\n",
       " 314: 'Qaida',\n",
       " 315: 'fighters',\n",
       " 316: 'Officials',\n",
       " 317: 'many',\n",
       " 318: 'Sunni',\n",
       " 319: 'Arab',\n",
       " 320: 'Kurdish',\n",
       " 321: 'bombings',\n",
       " 322: 'last',\n",
       " 323: '34',\n",
       " 324: 'people',\n",
       " 325: 'wounded',\n",
       " 326: '200',\n",
       " 327: 'commanders',\n",
       " 328: 'explained',\n",
       " 329: 'American',\n",
       " 330: 'forces',\n",
       " 331: 'participate',\n",
       " 332: 'fled',\n",
       " 333: 'successful',\n",
       " 334: 'campaigns',\n",
       " 335: 'them',\n",
       " 336: 'Anbar',\n",
       " 337: 'province',\n",
       " 338: 'Baghdad',\n",
       " 339: 'provinces',\n",
       " 340: 'largest',\n",
       " 341: 'north',\n",
       " 342: 'long',\n",
       " 343: 'stronghold',\n",
       " 344: 'militant',\n",
       " 345: 'In',\n",
       " 346: 'violence',\n",
       " 347: 'one',\n",
       " 348: 'soldier',\n",
       " 349: 'patrol',\n",
       " 350: 'Sunday',\n",
       " 351: 'Egyptian',\n",
       " 352: 'police',\n",
       " 353: 'arrested',\n",
       " 354: '16',\n",
       " 355: 'members',\n",
       " 356: 'opposition',\n",
       " 357: 'Muslim',\n",
       " 358: 'Brotherhood',\n",
       " 359: 'prepare',\n",
       " 360: 'parliamentary',\n",
       " 361: 'runoff',\n",
       " 362: 'elections',\n",
       " 363: 'Saturday',\n",
       " 364: 'arrests',\n",
       " 365: 'Friday',\n",
       " 366: 'Alexandria',\n",
       " 367: 'A',\n",
       " 368: 'spokesman',\n",
       " 369: 'attempt',\n",
       " 370: 'cut',\n",
       " 371: 'off',\n",
       " 372: 'supporters',\n",
       " 373: 'punishment',\n",
       " 374: 'winning',\n",
       " 375: 'seats',\n",
       " 376: 'earlier',\n",
       " 377: 'tripled',\n",
       " 378: 'strength',\n",
       " 379: 'parliament',\n",
       " 380: 'recent',\n",
       " 381: 'raising',\n",
       " 382: 'total',\n",
       " 383: '47',\n",
       " 384: 'voters',\n",
       " 385: 'cast',\n",
       " 386: 'ballots',\n",
       " 387: 'nine',\n",
       " 388: 'no',\n",
       " 389: 'candidate',\n",
       " 390: 'won',\n",
       " 391: 'majority',\n",
       " 392: 'previous',\n",
       " 393: 'round',\n",
       " 394: 'voting',\n",
       " 395: 'banned',\n",
       " 396: 'political',\n",
       " 397: 'but',\n",
       " 398: 'endorses',\n",
       " 399: 'so-called',\n",
       " 400: 'independent',\n",
       " 401: 'candidates',\n",
       " 402: 'whose',\n",
       " 403: 'allegiance',\n",
       " 404: 'known',\n",
       " 405: 'Hardline',\n",
       " 406: 'lawmakers',\n",
       " 407: 'Pakistan',\n",
       " 408: 'North',\n",
       " 409: 'West',\n",
       " 410: 'Frontier',\n",
       " 411: 'Province',\n",
       " 412: 'pushed',\n",
       " 413: 'law',\n",
       " 414: 'aims',\n",
       " 415: 'ensure',\n",
       " 416: 'Islamic',\n",
       " 417: 'correctness',\n",
       " 418: 'public',\n",
       " 419: 'places',\n",
       " 420: 'establishes',\n",
       " 421: 'morality',\n",
       " 422: 'enforce',\n",
       " 423: 'decent',\n",
       " 424: 'behavior',\n",
       " 425: 'six-party',\n",
       " 426: 'coalition',\n",
       " 427: 'religious',\n",
       " 428: 'based',\n",
       " 429: 'parties',\n",
       " 430: 'Mutahida',\n",
       " 431: 'Majlis-e-Amal',\n",
       " 432: 'dominates',\n",
       " 433: 'provincial',\n",
       " 434: 'assembly',\n",
       " 435: 'so',\n",
       " 436: 'bill',\n",
       " 437: 'easily',\n",
       " 438: 'passed',\n",
       " 439: 'Thursday',\n",
       " 440: 'vote',\n",
       " 441: '68-34',\n",
       " 442: 'governor',\n",
       " 443: 'must',\n",
       " 444: 'still',\n",
       " 445: 'sign',\n",
       " 446: 'before',\n",
       " 447: 'becomes',\n",
       " 448: 'seen',\n",
       " 449: 'only',\n",
       " 450: 'formality',\n",
       " 451: 'proposed',\n",
       " 452: 'calls',\n",
       " 453: 'setting',\n",
       " 454: 'up',\n",
       " 455: 'force',\n",
       " 456: 'make',\n",
       " 457: 'sure',\n",
       " 458: 'adhere',\n",
       " 459: 'values',\n",
       " 460: 'entertainment',\n",
       " 461: 'outlets',\n",
       " 462: 'close',\n",
       " 463: 'weekly',\n",
       " 464: 'prayers',\n",
       " 465: 'Violators',\n",
       " 466: 'be',\n",
       " 467: 'jailed',\n",
       " 468: 'six',\n",
       " 469: 'months',\n",
       " 470: 'denounced',\n",
       " 471: 'measure',\n",
       " 472: 'comparing',\n",
       " 473: 'draconian',\n",
       " 474: 'rule',\n",
       " 475: 'former',\n",
       " 476: 'Taleban',\n",
       " 477: 'neighboring',\n",
       " 478: 'Afghanistan',\n",
       " 479: 'man',\n",
       " 480: 'dressed',\n",
       " 481: 'suicide',\n",
       " 482: 'bomber',\n",
       " 483: 'demonstration',\n",
       " 484: 'publication',\n",
       " 485: 'cartoons',\n",
       " 486: 'depicting',\n",
       " 487: 'Islam',\n",
       " 488: 'Prophet',\n",
       " 489: 'Muhammad',\n",
       " 490: 'Bedfordshire',\n",
       " 491: 'Omar',\n",
       " 492: 'Khayam',\n",
       " 493: 'Bedford',\n",
       " 494: 'breaching',\n",
       " 495: 'conditions',\n",
       " 496: 'his',\n",
       " 497: 'parole',\n",
       " 498: 'Home',\n",
       " 499: 'Office',\n",
       " 500: 'sought',\n",
       " 501: 'investigation',\n",
       " 502: 'he',\n",
       " 503: 'photographed',\n",
       " 504: 'fatigues',\n",
       " 505: 'black',\n",
       " 506: 'cap',\n",
       " 507: 'bulky',\n",
       " 508: 'belt',\n",
       " 509: 'told',\n",
       " 510: 'Associated',\n",
       " 511: 'Press',\n",
       " 512: 'paroled',\n",
       " 513: 'offender',\n",
       " 514: 'gives',\n",
       " 515: 'cause',\n",
       " 516: 'concern',\n",
       " 517: 'can',\n",
       " 518: 'sent',\n",
       " 519: 'back',\n",
       " 520: 'prison',\n",
       " 521: 'AP',\n",
       " 522: 'also',\n",
       " 523: 'since',\n",
       " 524: 'year',\n",
       " 525: 'serving',\n",
       " 526: 'half',\n",
       " 527: 'six-year',\n",
       " 528: 'sentence',\n",
       " 529: 'drug',\n",
       " 530: 'dealing',\n",
       " 531: 'Pakistani',\n",
       " 532: 'unidentified',\n",
       " 533: 'three',\n",
       " 534: 'minister',\n",
       " 535: 'semi-autonomous',\n",
       " 536: 'bordering',\n",
       " 537: 'prominent',\n",
       " 538: 'leader',\n",
       " 539: 'Malik',\n",
       " 540: 'Faridullah',\n",
       " 541: 'Khan',\n",
       " 542: 'traveling',\n",
       " 543: 'South',\n",
       " 544: 'Waziristan',\n",
       " 545: 'vehicle',\n",
       " 546: 'ambushed',\n",
       " 547: 'Kani',\n",
       " 548: 'Wam',\n",
       " 549: 'area',\n",
       " 550: 'His',\n",
       " 551: 'driver',\n",
       " 552: 'elder',\n",
       " 553: 'No',\n",
       " 554: 'responsibility',\n",
       " 555: 'killings',\n",
       " 556: 'ambush',\n",
       " 557: 'commander',\n",
       " 558: 'army',\n",
       " 559: 'almost',\n",
       " 560: 'completely',\n",
       " 561: 'eliminated',\n",
       " 562: 'became',\n",
       " 563: 'refuge',\n",
       " 564: 'al-Qaida',\n",
       " 565: 'ousted',\n",
       " 566: '2001',\n",
       " 567: 'senior',\n",
       " 568: 'says',\n",
       " 569: 'wants',\n",
       " 570: 'what',\n",
       " 571: 'sordid',\n",
       " 572: 'chapter',\n",
       " 573: 'proliferation',\n",
       " 574: 'top',\n",
       " 575: 'scientists',\n",
       " 576: 'behind',\n",
       " 577: 'build',\n",
       " 578: 'civilian',\n",
       " 579: 'ties',\n",
       " 580: 'United',\n",
       " 581: 'States',\n",
       " 582: 'But',\n",
       " 583: 'ready',\n",
       " 584: 'scientist',\n",
       " 585: 'Abdul',\n",
       " 586: 'Qadeer',\n",
       " 587: 'available',\n",
       " 588: 'direct',\n",
       " 589: 'questioning',\n",
       " 590: 'sale',\n",
       " 591: 'secrets',\n",
       " 592: 'states',\n",
       " 593: 'Libya',\n",
       " 594: 'Korea',\n",
       " 595: 'He',\n",
       " 596: 'there',\n",
       " 597: 'reasons',\n",
       " 598: 'national',\n",
       " 599: 'sensitivities',\n",
       " 600: 'making',\n",
       " 601: 'him',\n",
       " 602: 'giving',\n",
       " 603: 'background',\n",
       " 604: 'briefing',\n",
       " 605: 'small',\n",
       " 606: 'group',\n",
       " 607: 'reporters',\n",
       " 608: 'Washington',\n",
       " 609: 'admitted',\n",
       " 610: '2004',\n",
       " 611: 'operated',\n",
       " 612: 'worldwide',\n",
       " 613: 'clandestine',\n",
       " 614: 'network',\n",
       " 615: 'sell',\n",
       " 616: 'technology',\n",
       " 617: 'market',\n",
       " 618: 'placed',\n",
       " 619: 'under',\n",
       " 620: 'house',\n",
       " 621: 'arrest',\n",
       " 622: 'Islamabad',\n",
       " 623: 'because',\n",
       " 624: 'considered',\n",
       " 625: 'father',\n",
       " 626: 'bomb',\n",
       " 627: 'Army',\n",
       " 628: 'renew',\n",
       " 629: 'controversial',\n",
       " 630: 'multi-billion',\n",
       " 631: 'dollar',\n",
       " 632: 'contract',\n",
       " 633: 'Halliburton',\n",
       " 634: 'company',\n",
       " 635: 'provide',\n",
       " 636: 'logistical',\n",
       " 637: 'support',\n",
       " 638: 'providing',\n",
       " 639: 'list',\n",
       " 640: 'meals',\n",
       " 641: 'communication',\n",
       " 642: 'several',\n",
       " 643: 'years',\n",
       " 644: 'Critics',\n",
       " 645: 'include',\n",
       " 646: 'auditors',\n",
       " 647: 'congressional',\n",
       " 648: 'Democrats',\n",
       " 649: 'produced',\n",
       " 650: 'some',\n",
       " 651: 'shoddy',\n",
       " 652: 'work',\n",
       " 653: 'charges',\n",
       " 654: 'too',\n",
       " 655: 'much',\n",
       " 656: 'money',\n",
       " 657: 'strongly',\n",
       " 658: 'denies',\n",
       " 659: 'allegations',\n",
       " 660: 'When',\n",
       " 661: 're-bidding',\n",
       " 662: 'chance',\n",
       " 663: 'compete',\n",
       " 664: 'portions',\n",
       " 665: 'Representatives',\n",
       " 666: 'Asia',\n",
       " 667: 'Pacific',\n",
       " 668: 'Economic',\n",
       " 669: 'Cooperation',\n",
       " 670: 'Business',\n",
       " 671: 'Advisory',\n",
       " 672: 'holding',\n",
       " 673: 'meetings',\n",
       " 674: 'finalize',\n",
       " 675: 'report',\n",
       " 676: 'APEC',\n",
       " 677: 'leaders',\n",
       " 678: 'summit',\n",
       " 679: 'September',\n",
       " 680: '8',\n",
       " 681: '9',\n",
       " 682: 'VOA',\n",
       " 683: 'Nancy-Amelia',\n",
       " 684: 'Collins',\n",
       " 685: 'Sydney',\n",
       " 686: 'security',\n",
       " 687: 'climate',\n",
       " 688: 'change',\n",
       " 689: 'World',\n",
       " 690: 'Trade',\n",
       " 691: 'Organization',\n",
       " 692: 'stalled',\n",
       " 693: 'negotiations',\n",
       " 694: 'investment',\n",
       " 695: 'all',\n",
       " 696: 'expected',\n",
       " 697: 'among',\n",
       " 698: 'major',\n",
       " 699: 'topics',\n",
       " 700: 'ABAC',\n",
       " 701: 'Tim',\n",
       " 702: 'Harcourt',\n",
       " 703: 'chief',\n",
       " 704: 'economist',\n",
       " 705: 'Australian',\n",
       " 706: 'Commission',\n",
       " 707: 'plays',\n",
       " 708: 'important',\n",
       " 709: 'role',\n",
       " 710: 'informing',\n",
       " 711: 'governments',\n",
       " 712: 'problems',\n",
       " 713: 'most',\n",
       " 714: 'thing',\n",
       " 715: 'business',\n",
       " 716: 'do',\n",
       " 717: 'tell',\n",
       " 718: 'logjams',\n",
       " 719: 'obstacles',\n",
       " 720: 'things',\n",
       " 721: 'improve',\n",
       " 722: 'I',\n",
       " 723: 'think',\n",
       " 724: 'actually',\n",
       " 725: 'played',\n",
       " 726: 'pretty',\n",
       " 727: 'good',\n",
       " 728: 'leadership',\n",
       " 729: 'talking',\n",
       " 730: 'about',\n",
       " 731: 'trade',\n",
       " 732: 'facilitation',\n",
       " 733: 'basically',\n",
       " 734: 'standards',\n",
       " 735: 'consistent',\n",
       " 736: 'harmonious',\n",
       " 737: 'across',\n",
       " 738: 'comprises',\n",
       " 739: 'private',\n",
       " 740: 'sector',\n",
       " 741: 'each',\n",
       " 742: '21',\n",
       " 743: 'economies',\n",
       " 744: 'meets',\n",
       " 745: 'times',\n",
       " 746: 'made',\n",
       " 747: 'permanent',\n",
       " 748: 'body',\n",
       " 749: '1995',\n",
       " 750: 'perspective',\n",
       " 751: 'within',\n",
       " 752: 'Members',\n",
       " 753: 'represent',\n",
       " 754: 'range',\n",
       " 755: 'sectors',\n",
       " 756: 'medium',\n",
       " 757: 'businesses',\n",
       " 758: 'need',\n",
       " 759: 'energy',\n",
       " 760: 'efficiency',\n",
       " 761: 'encourage',\n",
       " 762: 'conservation',\n",
       " 763: 'practices',\n",
       " 764: 'discuss',\n",
       " 765: 'ways',\n",
       " 766: 'enhance',\n",
       " 767: 'regional',\n",
       " 768: 'cooperation',\n",
       " 769: 'reckon',\n",
       " 770: \"'ll\",\n",
       " 771: 'talk',\n",
       " 772: 'little',\n",
       " 773: 'bit',\n",
       " 774: 'customs',\n",
       " 775: 'quarantine',\n",
       " 776: 'having',\n",
       " 777: 'arrangements',\n",
       " 778: 'around',\n",
       " 779: 'And',\n",
       " 780: 'want',\n",
       " 781: 'one-stop',\n",
       " 782: 'shop',\n",
       " 783: 'terms',\n",
       " 784: 'combining',\n",
       " 785: 'immigration',\n",
       " 786: 'together',\n",
       " 787: '…',\n",
       " 788: 'just',\n",
       " 789: 'streamlined',\n",
       " 790: 'provides',\n",
       " 791: 'certainty',\n",
       " 792: 'non-governmental',\n",
       " 793: 'formal',\n",
       " 794: 'dialogue',\n",
       " 795: 'present',\n",
       " 796: 'meeting',\n",
       " 797: 'Sudan',\n",
       " 798: 'order',\n",
       " 799: 'Darfur',\n",
       " 800: 'asking',\n",
       " 801: 'same',\n",
       " 802: 'Foreign',\n",
       " 803: 'Minister',\n",
       " 804: 'Mustafa',\n",
       " 805: 'Osman',\n",
       " 806: 'Ismail',\n",
       " 807: 'Sudanese',\n",
       " 808: 'withdraw',\n",
       " 809: 'positions',\n",
       " 810: 'held',\n",
       " 811: 'April',\n",
       " 812: 'cease-fire',\n",
       " 813: 'western',\n",
       " 814: 'agree',\n",
       " 815: 'stop',\n",
       " 816: 'Mr.',\n",
       " 817: 'announced',\n",
       " 818: 'decision',\n",
       " 819: 'Nations',\n",
       " 820: 'African',\n",
       " 821: 'Khartoum',\n",
       " 822: 'weeks',\n",
       " 823: 'AU',\n",
       " 824: 'repeatedly',\n",
       " 825: 'truce',\n",
       " 826: 'head',\n",
       " 827: 'accused',\n",
       " 828: 'helicopters',\n",
       " 829: 'bombing',\n",
       " 830: 'rebel',\n",
       " 831: 'sites',\n",
       " 832: 'village',\n",
       " 833: 'Labado',\n",
       " 834: 'defending',\n",
       " 835: 'Aid',\n",
       " 836: 'relief',\n",
       " 837: 'efforts',\n",
       " 838: 'suspended',\n",
       " 839: 'due',\n",
       " 840: 'Indonesian',\n",
       " 841: 'men',\n",
       " 842: 'connection',\n",
       " 843: 'October',\n",
       " 844: '1',\n",
       " 845: 'Bali',\n",
       " 846: 'left',\n",
       " 847: '23',\n",
       " 848: 'dead',\n",
       " 849: 'flown',\n",
       " 850: 'Java',\n",
       " 851: 'island',\n",
       " 852: 'headquarters',\n",
       " 853: 'French',\n",
       " 854: 'agencies',\n",
       " 855: '(',\n",
       " 856: 'Cholily',\n",
       " 857: ')',\n",
       " 858: 'captured',\n",
       " 859: 'series',\n",
       " 860: 'counter-terrorism',\n",
       " 861: 'raids',\n",
       " 862: 'Indonesia',\n",
       " 863: 'ended',\n",
       " 864: 'death',\n",
       " 865: 'alleged',\n",
       " 866: 'extremist',\n",
       " 867: 'bombmaker',\n",
       " 868: 'Azahari',\n",
       " 869: 'bin',\n",
       " 870: 'Husin',\n",
       " 871: 'authorities',\n",
       " 872: 'blame',\n",
       " 873: 'orchestrating',\n",
       " 874: 'month',\n",
       " 875: 'well',\n",
       " 876: '2002',\n",
       " 877: 'Gunmen',\n",
       " 878: 'shot',\n",
       " 879: 'Roman',\n",
       " 880: 'Catholic',\n",
       " 881: 'nun',\n",
       " 882: 'her',\n",
       " 883: 'bodyguard',\n",
       " 884: 'hospital',\n",
       " 885: 'she',\n",
       " 886: 'worked',\n",
       " 887: 'Islamist-controlled',\n",
       " 888: 'Some',\n",
       " 889: 'witnesses',\n",
       " 890: 'shooting',\n",
       " 891: 'feared',\n",
       " 892: 'linked',\n",
       " 893: 'anger',\n",
       " 894: 'toward',\n",
       " 895: 'Pope',\n",
       " 896: 'Benedict',\n",
       " 897: 'pistols',\n",
       " 898: 'attacked',\n",
       " 899: 'Sister',\n",
       " 900: 'Leonella',\n",
       " 901: 'Sgorbati',\n",
       " 902: 'finished',\n",
       " 903: 'teaching',\n",
       " 904: 'medical',\n",
       " 905: 'school',\n",
       " 906: 'class',\n",
       " 907: 'suspect',\n",
       " 908: 'Vatican',\n",
       " 909: 'deplored',\n",
       " 910: 'hoped',\n",
       " 911: 'isolated',\n",
       " 912: 'event',\n",
       " 913: 'irrationality',\n",
       " 914: 'arising',\n",
       " 915: 'comments',\n",
       " 916: 'angered',\n",
       " 917: 'Muslims',\n",
       " 918: 'Authorities',\n",
       " 919: 'determined',\n",
       " 920: 'motive',\n",
       " 921: 'pope',\n",
       " 922: 'meant',\n",
       " 923: 'offense',\n",
       " 924: 'quoted',\n",
       " 925: '14',\n",
       " 926: 'century',\n",
       " 927: 'Byzantine',\n",
       " 928: 'emperor',\n",
       " 929: 'saying',\n",
       " 930: 'teachings',\n",
       " 931: 'Muhammed',\n",
       " 932: 'brought',\n",
       " 933: 'evil',\n",
       " 934: 'world',\n",
       " 935: 'targeted',\n",
       " 936: 'northwest',\n",
       " 937: 'third',\n",
       " 938: 'launching',\n",
       " 939: 'airstrikes',\n",
       " 940: 'suspected',\n",
       " 941: 'insurgents',\n",
       " 942: 'Helicopter',\n",
       " 943: 'gunships',\n",
       " 944: 'pounded',\n",
       " 945: 'hideouts',\n",
       " 946: 'Orakzai',\n",
       " 947: 'Taliban',\n",
       " 948: 'believed',\n",
       " 949: 'avoid',\n",
       " 950: 'nearby',\n",
       " 951: 'launched',\n",
       " 952: 'hunt',\n",
       " 953: 'So',\n",
       " 954: 'far',\n",
       " 955: 'nearly',\n",
       " 956: '100',\n",
       " 957: 'reported',\n",
       " 958: 'On',\n",
       " 959: 'dozens',\n",
       " 960: 'stormed',\n",
       " 961: 'checkpoint',\n",
       " 962: 'At',\n",
       " 963: '32',\n",
       " 964: 'counter-attack',\n",
       " 965: 'Elsewhere',\n",
       " 966: 'found',\n",
       " 967: 'bodies',\n",
       " 968: 'had',\n",
       " 969: 'Kurram',\n",
       " 970: 'along',\n",
       " 971: 'Afghan',\n",
       " 972: 'border',\n",
       " 973: 'few',\n",
       " 974: 'days',\n",
       " 975: 'ago',\n",
       " 976: 'separate',\n",
       " 977: 'clashes',\n",
       " 978: '13',\n",
       " 979: 'guerrillas',\n",
       " 980: 'two',\n",
       " 981: 'encounters',\n",
       " 982: 'central',\n",
       " 983: 'Uruzgan',\n",
       " 984: 'others',\n",
       " 985: 'injured',\n",
       " 986: 'fighting',\n",
       " 987: 'Another',\n",
       " 988: 'eastern',\n",
       " 989: 'Paktika',\n",
       " 990: 'Separately',\n",
       " 991: 'NATO-led',\n",
       " 992: 'peacekeeping',\n",
       " 993: 'mission',\n",
       " 994: 'early',\n",
       " 995: 'Mazar-e-Sharif',\n",
       " 996: 'motivated',\n",
       " 997: 'spared',\n",
       " 998: 'bloodshed',\n",
       " 999: 'plagued',\n",
       " ...}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_vocab_map = {v:k for k, v in vocab.items()}\n",
    "reverse_vocab_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc786f0b-718f-4c70-9878-565ba4fedc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "red = \"\\033[1;31m\"\n",
    "green = \"\\033[1;32m\"\n",
    "purple= \"\\033[1;35m\"\n",
    "reset= \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1a80ed7a-8f92-4569-a0da-a8b373b68ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Token |    Pred | True NER Tag\n",
      "----------------------------------------------------------------------\n",
      "                  In |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                1861 |      \u001b[1;31mO\u001b[0m  | \u001b[1;35mB-tim\u001b[0m\n",
      "                   , |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 the |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "          Dominicans |      \u001b[1;31mO\u001b[0m  | \u001b[1;35mB-gpe\u001b[0m\n",
      "         voluntarily |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "            returned |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                  to |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 the |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "             Spanish |  \u001b[1;32mB-gpe\u001b[0m  | \u001b[1;35mB-gpe\u001b[0m\n",
      "              Empire |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                   , |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 but |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 two |      \u001b[1;31mO\u001b[0m  | \u001b[1;35mB-tim\u001b[0m\n",
      "               years |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "               later |  \u001b[1;32mB-tim\u001b[0m  | \u001b[1;35mB-tim\u001b[0m\n",
      "                they |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "            launched |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                   a |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 war |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                that |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "            restored |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "        independence |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                  in |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                1865 |  \u001b[1;32mB-tim\u001b[0m  | \u001b[1;35mB-tim\u001b[0m\n",
      "                   . |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sentence = [reverse_vocab_map[i.item()] for i in x_test[0][mask].detach().cpu()]\n",
    "pred_tags_converted = [reverse_tag_map[i.item()] for i in pred_tags[0][mask]]\n",
    "true_tags_converted = [reverse_tag_map[i.item()] for i in y_test[0][mask]]\n",
    "\n",
    "print(\"{:>20} | {:>7} | {:>5}\".format(\"Token\", \"Pred\", \"True NER Tag\"))\n",
    "print('-'*70)\n",
    "for s, p, t in zip(sentence, pred_tags_converted, true_tags_converted):\n",
    "    if p == t:\n",
    "        p = green + p + reset\n",
    "    else:\n",
    "        p = red + p + reset\n",
    "    t = purple + t + reset\n",
    "    print(\"{:>20} | {:>17}  | {:>15}\".format(s, p, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "50c41e8b-cd6c-49e5-8a22-10b4ffc06e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_id = random.randint(0, len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "939301cd-c0c6-43d5-a3ff-2a8cd1927c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Token |    Pred | True Tag\n",
      "----------------------------------------------------------------------\n",
      "               There |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 has |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                been |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                  no |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                U.S. |  \u001b[1;32mB-geo\u001b[0m  | \u001b[1;35mB-geo\u001b[0m\n",
      "             comment |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                  on |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 the |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "              report |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                   . |      \u001b[1;32mO\u001b[0m  |    \u001b[1;35mO\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mask = y_test[random_id] != vocab['<PAD>']\n",
    "sentence = [reverse_vocab_map[i.item()] for i in x_test[random_id][mask].detach().cpu()]\n",
    "pred_tags_converted = [reverse_tag_map[i.item()] for i in pred_tags[random_id][mask]]\n",
    "true_tags_converted = [reverse_tag_map[i.item()] for i in y_test[random_id][mask]]\n",
    "\n",
    "print(\"{:>20} | {:>7} | {:>5}\".format(\"Token\", \"Pred\", \"True Tag\"))\n",
    "print('-'*70)\n",
    "for s, p, t in zip(sentence, pred_tags_converted, true_tags_converted):\n",
    "    if p == t:\n",
    "        p = green + p + reset\n",
    "    else:\n",
    "        p = red + p + reset\n",
    "    t = purple + t + reset\n",
    "    print(\"{:>20} | {:>17}  | {:>15}\".format(s, p, t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b5d6bd-ba0a-4746-a241-563c919b3d5c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Transformers (Hugging Face)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc04f1b-6201-4429-a2f0-42048488dcdb",
   "metadata": {},
   "source": [
    "**These below steps will necessary for NER**\n",
    "\n",
    "- Read text lines and split them into tokens i.e. pre-tokenize using spaces. Clean the data before if necessary\n",
    "    - sentences = [list of [list of tokens for each sentence] each with dynamic length]\n",
    "    - labels = [list of [list of label-tags for each token] each with dynamic length but same as its corresponding list]\n",
    "    \n",
    "- Re-tokenize eaech sentence with the corresponding model tokenizer of interest and get the offset mapping\n",
    "    - *make auto padding* = True\n",
    "    - *is_split_into_words* = True\n",
    "    - *return_offset* = True\n",
    "    - *truncation* = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4194d709-0be9-484b-b242-79d3033db3ed",
   "metadata": {},
   "source": [
    "## Model Specific Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93ab88b8-984f-429f-9b68-917a64f59d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5a571f79-37ba-4520-85de-ba361aaf2e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta = 'roberta-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "aa74d296-9d02-454c-9d41-32053ad3e719",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(roberta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "607aff43-7153-4957-bf70-35dcbc9dcaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a statement Monday , Mr. Peres said \" there exists no basis in reality for the claims published \" by the British newspaper , The Guardian .'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset.sentences[rand_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b1933f0-6ceb-4c99-9717-68493c83328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'In', 'Ġa', 'Ġstatement', 'ĠMonday', 'Ġ,', 'ĠMr', '.', 'ĠPe', 'res', 'Ġsaid', 'Ġ\"', 'Ġthere', 'Ġexists', 'Ġno', 'Ġbasis', 'Ġin', 'Ġreality', 'Ġfor', 'Ġthe', 'Ġclaims', 'Ġpublished', 'Ġ\"', 'Ġby', 'Ġthe', 'ĠBritish', 'Ġnewspaper', 'Ġ,', 'ĠThe', 'ĠGuardian', 'Ġ.', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(roberta_tokenizer(train_loader.dataset.sentences[rand_id], truncation=True, padding=True).tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7399d10c-3739-4939-94dd-2e02c035ffbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenized = roberta_tokenizer(train_loader.dataset.sentences[rand_id], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e6f626bd-1c11-47a1-bd6f-653951e7341d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f2259551-59e8-40be-bff5-8e7e6935edfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_bert = RobertaTokenizerFast.from_pretrained('roberta-base', add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "92d3e58d-9eb0-44a7-a327-41cc90793c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 96, 10, 445, 302, 2156, 427, 4, 4119, 1535, 26, 22, 89, 8785, 117, 1453, 11, 2015, 13, 5, 1449, 1027, 22, 30, 5, 1089, 2924, 2156, 20, 8137, 479, 2, 1, 1, 1, 1, 1, 1], [0, 427, 4, 4119, 1535, 26, 20, 8137, 875, 63, 1566, 716, 15, 5, 22, 21921, 13794, 9, 391, 1704, 2339, 8, 45, 15, 6369, 4905, 479, 22, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 20, 266, 1027, 395, 5304, 3862, 703, 391, 1704, 2339, 59, 299, 3556, 2891, 11, 61, 427, 4, 4119, 1535, 2346, 1661, 5, 37449, 7, 391, 1704, 503, 11, 14873, 479, 2, 1, 1, 1, 1, 1], [0, 1870, 34, 393, 1474, 50, 2296, 5, 3924, 547, 6563, 14, 24, 34, 1748, 2398, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 391, 1327, 2226, 1748, 2398, 148, 1104, 5688, 2178, 2156, 53, 31088, 63, 1748, 586, 11, 9633, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 1557, 1939, 1984, 4282, 1284, 161, 114, 2736, 394, 37, 708, 7, 146, 1564, 4555, 13, 961, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 3580, 7, 521, 23, 10, 435, 1564, 11, 2293, 294, 2156, 1284, 3373, 484, 5287, 37, 161, 37, 74, 5731, 217, 10, 68, 204, 6, 151, 629, 1361, 13, 521, 54, 64, 45, 4960, 1564, 479, 2], [0, 91, 67, 26, 37, 74, 2703, 1294, 2973, 28, 1286, 30, 5, 752, 168, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 20, 3882, 6704, 26, 89, 74, 28, 3471, 7, 1325, 5, 629, 1361, 2156, 217, 727, 722, 9, 435, 544, 479, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 374, 302, 2156, 320, 121, 4, 104, 4, 3287, 270, 726, 16603, 11585, 1284, 2156, 584, 11, 2921, 2156, 2293, 2156, 14, 1284, 16, 5, 1984, 7, 483, 5, 247, 1706, 10, 357, 499, 479, 2, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]], 'offset_mapping': [[(0, 0), (0, 2), (0, 1), (0, 9), (0, 6), (0, 1), (0, 2), (2, 3), (0, 2), (2, 5), (0, 4), (0, 1), (0, 5), (0, 6), (0, 2), (0, 5), (0, 2), (0, 7), (0, 3), (0, 3), (0, 6), (0, 9), (0, 1), (0, 2), (0, 3), (0, 7), (0, 9), (0, 1), (0, 3), (0, 8), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], [(0, 0), (0, 2), (2, 3), (0, 2), (2, 5), (0, 4), (0, 3), (0, 8), (0, 5), (0, 3), (0, 7), (0, 5), (0, 2), (0, 3), (0, 1), (0, 9), (0, 14), (0, 2), (0, 5), (0, 7), (0, 9), (0, 3), (0, 3), (0, 2), (0, 8), (0, 5), (0, 1), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], [(0, 0), (0, 3), (0, 6), (0, 9), (0, 6), (0, 6), (0, 5), (0, 8), (0, 5), (0, 7), (0, 9), (0, 5), (0, 3), (0, 6), (0, 8), (0, 2), (0, 5), (0, 2), (2, 3), (0, 2), (2, 5), (0, 9), (0, 7), (0, 3), (0, 8), (0, 2), (0, 5), (0, 7), (0, 9), (0, 2), (0, 4), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], [(0, 0), (0, 6), (0, 3), (0, 5), (0, 9), (0, 2), (0, 6), (0, 3), (0, 6), (0, 4), (0, 6), (0, 4), (0, 2), (0, 3), (0, 7), (0, 7), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], [(0, 0), (0, 5), (0, 6), (0, 9), (0, 7), (0, 7), (0, 6), (0, 5), (0, 8), (0, 4), (0, 1), (0, 3), (0, 10), (0, 3), (0, 7), (0, 7), (0, 2), (0, 4), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], [(0, 0), (0, 10), (0, 12), (0, 9), (0, 6), (0, 5), (0, 4), (0, 2), (0, 7), (0, 9), (0, 2), (0, 5), (0, 2), (0, 4), (0, 7), (0, 10), (0, 3), (0, 8), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], [(0, 0), (0, 8), (0, 2), (0, 8), (0, 2), (0, 1), (0, 9), (0, 7), (0, 2), (0, 8), (0, 7), (0, 1), (0, 5), (0, 9), (0, 7), (0, 11), (0, 2), (0, 4), (0, 2), (0, 5), (0, 9), (0, 9), (0, 1), (0, 1), (0, 1), (1, 2), (2, 5), (0, 3), (0, 6), (0, 3), (0, 8), (0, 3), (0, 3), (0, 3), (0, 6), (0, 7), (0, 1), (0, 0)], [(0, 0), (0, 2), (0, 4), (0, 4), (0, 2), (0, 5), (0, 7), (0, 7), (0, 5), (0, 2), (0, 8), (0, 2), (0, 3), (0, 7), (0, 10), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], [(0, 0), (0, 3), (0, 8), (0, 7), (0, 4), (0, 5), (0, 5), (0, 2), (0, 12), (0, 2), (0, 7), (0, 3), (0, 3), (0, 6), (0, 1), (0, 9), (0, 3), (0, 5), (0, 2), (0, 9), (0, 7), (0, 1), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0), (0, 0)], [(0, 0), (0, 2), (0, 6), (0, 1), (0, 6), (0, 1), (1, 2), (2, 3), (3, 4), (0, 4), (0, 9), (0, 2), (0, 4), (0, 8), (0, 5), (0, 1), (0, 6), (0, 2), (0, 7), (0, 1), (0, 8), (0, 1), (0, 4), (0, 5), (0, 2), (0, 3), (0, 9), (0, 2), (0, 4), (0, 3), (0, 7), (0, 6), (0, 1), (0, 6), (0, 6), (0, 1), (0, 0), (0, 0)]]}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_texts = [train_loader.dataset.sentences[i].split() for i in range(rand_id, rand_id + 10)]\n",
    "roberta_encodings = roberta_bert(sample_texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
    "roberta_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1684cbd7-db61-48c9-b318-947ddc6a00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels = [train_loader.dataset.labels[i].split() for i in range(rand_id, rand_id + 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dd37d73c-3f5c-48ea-bda3-18216d21c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_labels_id = [[tag_map[i] for i in label] for label in sample_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1130dce8-b7bb-469e-b6f0-5f9b8b6863b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels_array = []\n",
    "for labels, offset_map in zip(sample_labels_id, roberta_encodings.offset_mapping):\n",
    "    # Creating empty array of size offset_map\n",
    "    encoded_labels = np.ones(len(offset_map)) * -100\n",
    "    offset_map = np.array(offset_map)\n",
    "    # The offset maps will have starting index = 0 if tokenized normally\n",
    "    # If subword tokenization happens then offset_i at index[0] = offset_(i-1) index[1]\n",
    "    encoded_labels[(offset_map[:,0] == 0) & (offset_map[:,1] != 0)] = labels\n",
    "    \n",
    "    encoded_labels_array.append(encoded_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "46cf8bdf-36e8-42ec-8719-bcbe00e5b678",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaNERDataset(Dataset):\n",
    "    def __init__(self, sentence_encodings, encoded_labels):\n",
    "        self.sentence_encodings = sentence_encodings\n",
    "        self.encoded_labels = encoded_labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Sentence Encodings are structured in:\n",
    "        \n",
    "            {\n",
    "            'input_ids': [[...], [...], [...]]\n",
    "            'attention_mask': [[...], [...], [...]]            \n",
    "            }\n",
    "            \n",
    "        Return a dictionary with the requested index\n",
    "        \n",
    "        {\n",
    "            'input_ids': tensor([encoded sentence at idx])\n",
    "            'attention_mask': tensor([attention at idx])\n",
    "            'labels': tensor([encoded labels at idx])        \n",
    "        }\n",
    "        \n",
    "        \"\"\"\n",
    "        item = {key: torch.tensor(val[idx], dtype=torch.long) for key, val in self.sentence_encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.encoded_labels[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "207aceb8-92f3-408e-8da6-ac477c7b9e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_encodings.pop(\"offset_mapping\") # we don't want to pass this to the model\n",
    "train_dataset = RobertaNERDataset(roberta_encodings, encoded_labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "afcb865d-2cec-44a5-becc-d4e93da4f6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8d1a227-54f5-4e13-9a54-e9c4fccf2375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'In', 'a', 'statement', 'Monday', ',', 'Mr', '.', 'Per', '##es', 'said', '\"', 'there', 'exists', 'no', 'basis', 'in', 'reality', 'for', 'the', 'claims', 'published', '\"', 'by', 'the', 'British', 'newspaper', ',', 'The', 'Guardian', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(bert_tokenizer(train_loader.dataset.sentences[rand_id]).tokens())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b82ed1-78b6-4eff-b64d-731c0f9ff23c",
   "metadata": {},
   "source": [
    "## Defining Fine-Tune Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d76cc6d1-5c16-4fdd-8eef-dcd7a93be5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import RobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9af88176-0f34-4daf-9252-17517e3200a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'architectures': ['RobertaForMaskedLM'],\n",
       "  'attention_probs_dropout_prob': 0.1,\n",
       "  'bos_token_id': 0,\n",
       "  'eos_token_id': 2,\n",
       "  'hidden_act': 'gelu',\n",
       "  'hidden_dropout_prob': 0.1,\n",
       "  'hidden_size': 768,\n",
       "  'initializer_range': 0.02,\n",
       "  'intermediate_size': 3072,\n",
       "  'layer_norm_eps': 1e-05,\n",
       "  'max_position_embeddings': 514,\n",
       "  'model_type': 'roberta',\n",
       "  'num_attention_heads': 12,\n",
       "  'num_hidden_layers': 12,\n",
       "  'pad_token_id': 1,\n",
       "  'type_vocab_size': 1,\n",
       "  'vocab_size': 50265},\n",
       " {})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RobertaConfig.get_config_dict('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ba26249d-b9e7-4c18-a970-f8a1a97e313e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mTokenClassifierOutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mloss\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mlogits\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mattentions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Base class for outputs of token classification models.\n",
       "\n",
       "Args:\n",
       "    loss (`torch.FloatTensor` of shape `(1,)`, *optional*, returned when `labels` is provided) :\n",
       "        Classification loss.\n",
       "    logits (`torch.FloatTensor` of shape `(batch_size, sequence_length, config.num_labels)`):\n",
       "        Classification scores (before SoftMax).\n",
       "    hidden_states (`tuple(torch.FloatTensor)`, *optional*, returned when `output_hidden_states=True` is passed or when `config.output_hidden_states=True`):\n",
       "        Tuple of `torch.FloatTensor` (one for the output of the embeddings, if the model has an embedding layer, +\n",
       "        one for the output of each layer) of shape `(batch_size, sequence_length, hidden_size)`.\n",
       "\n",
       "        Hidden-states of the model at the output of each layer plus the optional initial embedding outputs.\n",
       "    attentions (`tuple(torch.FloatTensor)`, *optional*, returned when `output_attentions=True` is passed or when `config.output_attentions=True`):\n",
       "        Tuple of `torch.FloatTensor` (one for each layer) of shape `(batch_size, num_heads, sequence_length,\n",
       "        sequence_length)`.\n",
       "\n",
       "        Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n",
       "        heads.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/torch/lib/python3.8/site-packages/transformers/modeling_outputs.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?TokenClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c03d3b93-b3dd-4a9d-8059-5cccfc2252ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RobertaNER(RobertaPreTrainedModel):\n",
    "    config_class = RobertaConfig\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        self.num_labels = config.num_labels\n",
    "        \n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        \n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        \n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
    "        \n",
    "        outputs = self.roberta(input_ids, attention_mask, token_type_ids, **kwargs)\n",
    "        \n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        \n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        loss = None\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss_function = nn.CrossEntropyLoss()\n",
    "            loss = loss_function(logits.view(-1, logits.shape[2]), labels.view(-1))\n",
    "        \n",
    "        return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "73a7d4a2-65e5-4a73-91ce-cc227fc94616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aed05e4c-e5a6-4038-acfe-6399b4a377c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_custom_config = AutoConfig.from_pretrained(roberta, num_labels=len(tag_map), id2label=tag_map, label2id=reverse_tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "41d72ad0-7db3-4416-a50c-15d9111da813",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaNER: ['lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaNER from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaNER from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaNER were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'roberta.embeddings.position_ids', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "r_ner = RobertaNER.from_pretrained('roberta-base', config=roberta_custom_config).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "65110f2b-f2a0-4af0-af33-5d1b78918232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"_name_or_path\": \"roberta-base\",\n",
       "  \"architectures\": [\n",
       "    \"RobertaForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"B-art\": 8,\n",
       "    \"B-eve\": 14,\n",
       "    \"B-geo\": 1,\n",
       "    \"B-gpe\": 2,\n",
       "    \"B-nat\": 13,\n",
       "    \"B-org\": 5,\n",
       "    \"B-per\": 3,\n",
       "    \"B-tim\": 7,\n",
       "    \"I-art\": 9,\n",
       "    \"I-eve\": 15,\n",
       "    \"I-geo\": 4,\n",
       "    \"I-gpe\": 11,\n",
       "    \"I-nat\": 16,\n",
       "    \"I-org\": 6,\n",
       "    \"I-per\": 10,\n",
       "    \"I-tim\": 12,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-geo\",\n",
       "    \"2\": \"B-gpe\",\n",
       "    \"3\": \"B-per\",\n",
       "    \"4\": \"I-geo\",\n",
       "    \"5\": \"B-org\",\n",
       "    \"6\": \"I-org\",\n",
       "    \"7\": \"B-tim\",\n",
       "    \"8\": \"B-art\",\n",
       "    \"9\": \"I-art\",\n",
       "    \"10\": \"I-per\",\n",
       "    \"11\": \"I-gpe\",\n",
       "    \"12\": \"I-tim\",\n",
       "    \"13\": \"B-nat\",\n",
       "    \"14\": \"B-eve\",\n",
       "    \"15\": \"I-eve\",\n",
       "    \"16\": \"I-nat\"\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 514,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.18.0\",\n",
       "  \"type_vocab_size\": 1,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_custom_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cc7c0952-e935-42a2-bde0-5d66c5ad7c1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_custom_config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5e034502-808d-4571-a360-dcf2d730004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = roberta_tokenizer.encode(train_loader.dataset.sentences[rand_id], truncation=True, padding=True, return_tensors='pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "10fbcd49-8ff1-43bc-afad-b5f0e631b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = r_ner(input_ids).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97f2129a-7767-4845-8391-0119b35f225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tags = predictions.argmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa0b41ea-05b0-4049-b2fe-93c0f215fadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13, 13, 13, 13, 13, 13, 13, 13, 13, 10, 13, 13, 13, 10, 10, 13, 11, 16,\n",
       "         13, 11, 13, 10, 13, 13, 13, 13, 13, 13, 11,  6, 13, 13]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e96cb0cb-e56b-4361-bd5a-4d0365443517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader.dataset.labels[rand_id].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f90e98a5-15b2-4d80-a2e9-4a35eceedd7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([reverse_tag_map[i] for i in pred_tags[0].detach().cpu().numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1c4177d1-167e-43fa-b308-d42e3a8ebdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = roberta_tokenizer(train_loader.dataset.sentences[rand_id], truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c349822e-b6cd-41f6-90b1-f83129416696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'In',\n",
       " 'Ġa',\n",
       " 'Ġstatement',\n",
       " 'ĠMonday',\n",
       " 'Ġ,',\n",
       " 'ĠMr',\n",
       " '.',\n",
       " 'ĠPe',\n",
       " 'res',\n",
       " 'Ġsaid',\n",
       " 'Ġ\"',\n",
       " 'Ġthere',\n",
       " 'Ġexists',\n",
       " 'Ġno',\n",
       " 'Ġbasis',\n",
       " 'Ġin',\n",
       " 'Ġreality',\n",
       " 'Ġfor',\n",
       " 'Ġthe',\n",
       " 'Ġclaims',\n",
       " 'Ġpublished',\n",
       " 'Ġ\"',\n",
       " 'Ġby',\n",
       " 'Ġthe',\n",
       " 'ĠBritish',\n",
       " 'Ġnewspaper',\n",
       " 'Ġ,',\n",
       " 'ĠThe',\n",
       " 'ĠGuardian',\n",
       " 'Ġ.',\n",
       " '</s>']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer.convert_ids_to_tokens(tokenized['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c64773-cf43-468e-9013-eb99eabaa454",
   "metadata": {},
   "source": [
    "## Model Specific Detokenizer returning the actual sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6cf9d303-3e70-4f5f-96ae-cd522f3bd8f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In a statement Monday, Mr. Peres said \" there exists no basis in reality for the claims published \" by the British newspaper, The Guardian.'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer.decode(input_ids.detach().cpu()[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629da47b-43cc-45f7-86c1-0ffa80669c72",
   "metadata": {},
   "source": [
    "## Data Preparation for 🤗-Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8c726337-9180-44e0-b15d-090774b9a959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "train_data = iter(train_loader)\n",
    "sample_text_batch = train_data.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2276b962-149c-4a2d-8eb2-af9a2303d9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" What is the matter with your shirt ? \" inquired the Tramp .'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [reverse_vocab_map[i.item()] for i in sample_text_batch[0][10] if i.item() != vocab['<PAD>']]\n",
    "' '.join(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "19195dc6-1f40-439b-a538-a632192b3ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "dbert_tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cdf2ed6b-b44a-4664-99bf-2c49977897f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dbert = dbert_tokenizer(sample_text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8b3f5479-9d0e-4587-ba48-6eff5f784c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_roberta = roberta_tokenizer(' '.join(sample_text), return_offsets_mapping=True, padding=True, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5db396b5-829e-40ea-9d59-052a98516732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 113, 653, 16, 5, 948, 19, 110, 6399, 17487, 22, 38276, 5, 2393, 3914, 479, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (2, 6), (7, 9), (10, 13), (14, 20), (21, 25), (26, 30), (31, 36), (37, 38), (39, 40), (41, 49), (50, 53), (54, 56), (56, 59), (60, 61), (0, 0)]}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3736cf7b-b450-472b-95fd-121e32eb772c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 17)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_text), len(train_roberta.tokens())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3a82d81e-6101-426e-988d-8124b3697524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', 'What', 'is', 'the', 'matter', 'with', 'your', 'shirt', '?', '\"', 'inquired', 'the', 'Tramp', '.']\n",
      "['<s>', '\"', 'ĠWhat', 'Ġis', 'Ġthe', 'Ġmatter', 'Ġwith', 'Ġyour', 'Ġshirt', 'Ġ?', 'Ġ\"', 'Ġinquired', 'Ġthe', 'ĠTr', 'amp', 'Ġ.', '</s>']\n",
      "['[CLS]', '\"', 'What', 'is', 'the', 'matter', 'with', 'your', 'shirt', '?', '\"', 'inquired', 'the', 'T', '##ram', '##p', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(sample_text, train_roberta.tokens(), train_dbert.tokens(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc183ff-f901-477d-af5e-96369f7cc8d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fine-Tuning using 🤗-`Trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "991cbea4-6fce-4455-bb4e-be7d0691dca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "00e89d36-6288-4976-be24-985508e10281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa605388-fef8-4b3f-8d5f-f979ee84987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ner_data(sentences_path=train_sentence,\n",
    "                         labels_path=train_labels,\n",
    "                         vocab_map=vocab,\n",
    "                         tags_map=tag_map)\n",
    "valid_dataset = ner_data(sentences_path=valid_sentence,\n",
    "                         labels_path=valid_labels,\n",
    "                         vocab_map=vocab,\n",
    "                         tags_map=tag_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "0502e447-ac0e-4b86-a3a0-85d9b7519628",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=r_ner, \n",
    "                  args=training_args,\n",
    "                  train_dataset=train_dataset,\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "55987364-5588-43b3-b26f-d39542ca1cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/archie/miniconda3/envs/torch/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 10\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:00, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3, training_loss=2.8865461349487305, metrics={'train_runtime': 0.7213, 'train_samples_per_second': 41.589, 'train_steps_per_second': 4.159, 'total_flos': 581872459320.0, 'train_loss': 2.8865461349487305, 'epoch': 3.0})"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "68267373-2609-4e67-95e5-c0b764285e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7d1701a1-e47e-4f28-89f2-a8ecda30c5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-100,    0,    0,    0,    7,    0,    3, -100,   10, -100,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    2,    0,    0,    5,    6,    0, -100, -100, -100, -100, -100,\n",
       "        -100, -100])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z['input_ids'] = z['input_ids'].view(1, -1).to('cuda')\n",
    "z['attention_mask'] = z['attention_mask'].view(1, -1).to('cuda')\n",
    "z.pop('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0c0a230c-1838-43ec-af94-432cf74989c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    r_ner.eval()\n",
    "    preeds = r_ner(**z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b5206c7e-31c4-49ed-9144-41746ac11dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = preeds['logits'][0].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0f77b733-2b4e-43dd-bf2a-5584a08bc4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array([-100,    0,    0,    0,    7,    0,    3, -100,   10, -100,    0,    0,\n",
    "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
    "           0,    2,    0,    0,    5,    6,    0, -100, -100, -100, -100, -100,\n",
    "        -100, -100])\n",
    "mask = true_labels != -100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eb6b12-1472-4d01-95d3-f21282607422",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-weight:700;font-size:20px\">\n",
    "   Need to keep track of the pre model-specific tokenized text for validation\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "bd7fb50e-55f9-4aed-af78-4c78676832b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_text_reversed = sample_texts[0]\n",
    "true_tags_reversed = [reverse_tag_map[i] for i in true_labels[mask]]\n",
    "predicted_tags_reversed = [reverse_tag_map[i] for i in preds.argmax(-1)[mask]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "553012a7-6501-4aba-b086-1cc50cd72f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Token |    Pred | True NER Tag\n",
      "----------------------------------------------------------------------\n",
      "                  In |  \u001b[1;31mI-per\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                   a |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "           statement |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "              Monday |  \u001b[1;31mB-nat\u001b[0m  | \u001b[1;35mB-tim\u001b[0m\n",
      "                   , |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 Mr. |  \u001b[1;31mB-nat\u001b[0m  | \u001b[1;35mB-per\u001b[0m\n",
      "               Peres |  \u001b[1;31mB-nat\u001b[0m  | \u001b[1;35mI-per\u001b[0m\n",
      "                said |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                   \" |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "               there |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "              exists |  \u001b[1;31mI-per\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                  no |  \u001b[1;31mI-per\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "               basis |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                  in |  \u001b[1;31mI-gpe\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "             reality |  \u001b[1;31mI-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 for |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 the |  \u001b[1;31mI-gpe\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "              claims |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "           published |  \u001b[1;31mI-per\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                   \" |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                  by |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 the |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "             British |  \u001b[1;31mB-nat\u001b[0m  | \u001b[1;35mB-gpe\u001b[0m\n",
      "           newspaper |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                   , |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n",
      "                 The |  \u001b[1;31mI-gpe\u001b[0m  | \u001b[1;35mB-org\u001b[0m\n",
      "            Guardian |  \u001b[1;32mI-org\u001b[0m  | \u001b[1;35mI-org\u001b[0m\n",
      "                   . |  \u001b[1;31mB-nat\u001b[0m  |    \u001b[1;35mO\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"{:>20} | {:>7} | {:>5}\".format(\"Token\", \"Pred\", \"True NER Tag\"))\n",
    "print('-'*70)\n",
    "for s, p, t in zip(true_text_reversed, predicted_tags_reversed, true_tags_reversed):\n",
    "    if p == t:\n",
    "        p = green + p + reset\n",
    "    else:\n",
    "        p = red + p + reset\n",
    "    t = purple + t + reset\n",
    "    print(\"{:>20} | {:>17}  | {:>15}\".format(s, p, t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7def1c28-ec27-450d-b508-4c7bd6ef4b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  In,         O\n",
      "                   a,         O\n",
      "           statement,         O\n",
      "              Monday,     B-tim\n",
      "                   ,,         O\n",
      "                 Mr.,     B-per\n",
      "               Peres,     I-per\n",
      "                said,         O\n",
      "                   \",         O\n",
      "               there,         O\n",
      "              exists,         O\n",
      "                  no,         O\n",
      "               basis,         O\n",
      "                  in,         O\n",
      "             reality,         O\n",
      "                 for,         O\n",
      "                 the,         O\n",
      "              claims,         O\n",
      "           published,         O\n",
      "                   \",         O\n",
      "                  by,         O\n",
      "                 the,         O\n",
      "             British,     B-gpe\n",
      "           newspaper,         O\n",
      "                   ,,         O\n",
      "                 The,     B-org\n",
      "            Guardian,     I-org\n",
      "                   .,         O\n"
     ]
    }
   ],
   "source": [
    "for t, g in zip(sample_texts[0], sample_labels[0]):\n",
    "    print(f\"{t:>20}, {g:>9}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8da378e6-83d0-4f4a-81e0-cd2b51e9539c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In a statement Monday , Mr. Peres said \" there exists no basis in reality for the claims published \" by the British newspaper , The Guardian .',\n",
       " 28)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sample_texts[0]), len(sample_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c1e63b18-b78b-4727-b37e-d62adadaa3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(' In a statement Monday, Mr. Peres said \" there exists no basis in reality for the claims published \" by the British newspaper, The Guardian.',\n",
       " 25)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_text_reversed, len(true_text_reversed.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41559c9f-f807-4125-9898-592fed9000e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
